
#  Titanic Survival Prediction Model

## Overview

In this project, I built a machine learning model to predict the survival of passengers aboard the Titanic using the classic **Titanic Dataset**. The goal was to classify whether a passenger survived (`Survived = 1`) or not (`Survived = 0`) based on features like age, sex, passenger class, fare, and family connections.

I followed a complete data science pipeline that includes:

* Data preprocessing and cleaning
* Exploratory Data Analysis (EDA)
* Feature engineering
* Training a **Random Forest Classifier**
* Evaluating the model using classification metrics and visualizations

This project was implemented in Python using libraries such as `pandas`, `seaborn`, and `scikit-learn`.

---

##  What I Did â€“ Step-by-Step

### 1.  Importing Libraries

I started by importing all the essential Python libraries like `pandas`, `numpy`, `matplotlib`, `seaborn`, and several modules from `sklearn` for preprocessing, modeling, and evaluation.

---

### 2.  Loading and Previewing the Data

I loaded the dataset named `Titanic-Dataset.csv` into a DataFrame using `pandas` and explored its structure using functions like `.head()`, `.info()`, and `.describe()` to get a sense of what I was working with.

---

### 3.  Data Preprocessing

I cleaned the dataset by:

* Filling missing `Age` values with the median
* Replacing missing `Embarked` values with the mode
* Dropping columns that were not useful for prediction like `Cabin`, `Ticket`, and `Name`
* Converting categorical features like `Sex` and `Embarked` into numerical form using label encoding

This helped ensure that the data was clean and suitable for machine learning.

---

### 4.  Exploratory Data Analysis (EDA)

To understand the data better, I visualized:

* The overall survival distribution
* Survival rates based on `Sex`, `Pclass`, and `Age`
* Correlations between features using a heatmap

These visualizations helped me identify patterns and relationships. For instance, I noticed that females and 1st-class passengers had a higher chance of survival.

---

### 5.  Feature Engineering

To give the model more useful information, I created new features:

* `FamilySize`: by adding `SibSp` and `Parch`
* `IsAlone`: to indicate if the passenger was traveling alone

These engineered features helped enhance the modelâ€™s performance.

---

### 6.  Model Preparation

I split the data into training and test sets (80% train, 20% test) using `train_test_split`. I also scaled the numeric features using `StandardScaler` so that they had a consistent range, which is important for many machine learning algorithms.

---

### 7.  Model Training

For the model, I chose the **Random Forest Classifier** because of its robustness and performance on structured/tabular data. I trained it on the processed training set.

---

### 8.  Model Evaluation

After training the model, I evaluated it using:

* Accuracy score
* Confusion matrix
* Classification report including precision, recall, and F1-score

The model performed well and gave reliable predictions on the test set.

---

### 9.  Additional Insights

Finally, I examined feature importance from the Random Forest model to see which features had the most influence on predictions. Features like `Sex`, `Pclass`, `Fare`, and `Age` turned out to be the most impactful.

---

## ðŸ’¡ Key Highlights

* âœ… I handled missing data and cleaned the dataset effectively
* ðŸ“Š I used EDA to uncover meaningful survival trends
* ðŸ§  I engineered new features to improve model performance
* ðŸŒ² I trained a Random Forest model that gave solid predictions
* ðŸ“ˆ I evaluated the model using multiple performance metrics
* ðŸ’¬ I explored feature importance to interpret model behavior

---

Let me know if youâ€™d like me to convert this into a downloadable `README.md` file or help you upload it to your GitHub repo.
